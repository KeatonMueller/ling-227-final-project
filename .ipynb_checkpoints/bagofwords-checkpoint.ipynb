{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfile = r'C:\\Users\\shala\\classify3\\ling-227-final-project\\texts\\Pope\\Pope_train1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(txtfile, 'r', encoding='utf-8') as f:\n",
    "    ogtext = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-36b4312055e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('\\s', ' ', text)\n",
    "temp = [c for c in text if c not in string.punctuation]\n",
    "text_clean = ''.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = text_clean.split(' ')\n",
    "len(set(li))/len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "li2 = [lemm.lemmatize(wd, pos=\"v\") for wd in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(li2))/len(li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FreqDist(li2)\n",
    "fd\n",
    "\n",
    "topN = 100 ##param\n",
    "fd.most_common(topN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing: accept string text, return a list of word stems without punct\n",
    "def _preprocess(text):\n",
    "    text = re.sub('\\s', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    temp = [c for c in text if c not in string.punctuation]\n",
    "    text_clean = ''.join(temp)\n",
    "    \n",
    "    li = text_clean.split(' ')\n",
    "    lemm = WordNetLemmatizer()\n",
    "    wdlist = [lemm.lemmatize(wd, pos=\"v\") for wd in li if wd != '']\n",
    "    \n",
    "    return wdlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {'Alexander Pope': [ogtext]}\n",
    "topN = 100\n",
    "\n",
    "vocab = _getVocab(corpus, topN)\n",
    "cvect = CountVectorizer(input='content', \n",
    "                        preprocessor=_preprocess,\n",
    "                        stop_words=None, \n",
    "                        vocabulary=vocab)\n",
    "feat = cvect.fit_transform(ogtext)\n",
    "feat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Take author and input text, return df (Series) of profiles\n",
    "def _makeProfile(auth, text, topN):\n",
    "    wdlist = _preprocess(text)\n",
    "\n",
    "    totalvocab = len(wdlist)\n",
    "\n",
    "    fd = FreqDist(wdlist)\n",
    "    commonwords = dict(fd.most_common(topN))\n",
    "    df = pd.DataFrame.from_dict(commonwords, orient='index', columns=[auth])\n",
    "    df = df/totalvocab #normalize\n",
    "\n",
    "    #df.set_index([auth])\n",
    "    df = df.transpose()\n",
    "    #df['Author'] = auth\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert text to features: takes two lists of texts and authors, returns df of features\n",
    "def _makeFeatureMatrix(traindict, topN):\n",
    "    \n",
    "    featdf = pd.DataFrame()\n",
    "    \n",
    "    for auth in traindict:\n",
    "        \n",
    "        df = _makeProfile(auth, traindict[auth], topN)\n",
    "        \n",
    "        featdf = featdf.append(df) #, ignore_index=True)\n",
    "\n",
    "        #c = c + Counter(commonwords)\n",
    "            \n",
    "    featdf.fillna(0, inplace=True)\n",
    "    #vocab = c.keys()\n",
    "    \n",
    "    print(featdf.size)\n",
    "    return featdf\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert text to features: takes two lists of texts and authors, returns df of features\n",
    "def _makeFeatureMatrix2(texts, authors, topN):\n",
    "    \n",
    "    featdf = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(texts)):\n",
    "        txt = texts[i]\n",
    "        auth = authors[i]\n",
    "        \n",
    "        df = _makeProfile(auth, txt, topN)\n",
    "        \n",
    "        featdf = featdf.append(df) #, ignore_index=True)\n",
    "\n",
    "        #c = c + Counter(commonwords)\n",
    "            \n",
    "    featdf.fillna(0, inplace=True)\n",
    "    #vocab = c.keys()\n",
    "    \n",
    "    print(featdf.size)\n",
    "    return featdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read training data\n",
    "\n",
    "path = r'C:\\Users\\shala\\classify3\\ling-227-final-project\\texts'\n",
    "filedict = {'Alexander Pope':[r'\\Pope\\Pope_train1.txt', r'\\Pope\\Pope_train2.txt'],\n",
    "            'John Dryden': [r'\\Dryden\\Dryden_train1.txt', r'\\Dryden\\Dryden_train2.txt'],\n",
    "            'George Chapman':[r'\\Chapman\\Chapman_train1.txt', r'\\Chapman\\Chapman_train2.txt',\n",
    "                             r'\\Chapman\\Chapman_train3.txt', r'\\Chapman\\Chapman_train4.txt']}\n",
    "\n",
    "training_data = {'Alexander Pope':[], 'John Dryden':[], 'George Chapman':[]}\n",
    "\n",
    "for auth in filedict:\n",
    "    flist = filedict[auth]\n",
    "    #clist = []\n",
    "    content = ''\n",
    "    for fi in flist:\n",
    "        txtfile = path+fi\n",
    "        with open(txtfile, 'r', encoding='utf-8') as f:\n",
    "            ogtext = f.read()\n",
    "            training_data[auth].append(ogtext)\n",
    "            #clist.append(ogtext)\n",
    "            content = content+ogtext+' '\n",
    "    filedict[auth] = content\n",
    "\n",
    "#print(filedict)  \n",
    "## Q: how to separate each file into more equitable training samples \n",
    "## (to reflect document size rather than compiled works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>her</th>\n",
       "      <th>his</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>in</th>\n",
       "      <th>their</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.095960</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.003367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.003322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.068143</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.051107</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.020443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.006768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.072041</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.020583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.007407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     the       her       his       and        to        be  \\\n",
       "Alexander Pope  0.095960  0.008418  0.000000  0.040404  0.018519  0.013468   \n",
       "Alexander Pope  0.058140  0.003322  0.003322  0.029900  0.023256  0.008306   \n",
       "Alexander Pope  0.068143  0.006814  0.003407  0.051107  0.020443  0.011925   \n",
       "Alexander Pope  0.055838  0.003384  0.000000  0.037225  0.021997  0.011844   \n",
       "Alexander Pope  0.072041  0.022298  0.001715  0.044597  0.010292  0.012007   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "George Chapman  0.048000  0.024000  0.000000  0.032000  0.008000  0.032000   \n",
       "George Chapman  0.032000  0.000000  0.032000  0.032000  0.016000  0.016000   \n",
       "George Chapman  0.038462  0.000000  0.061538  0.015385  0.015385  0.000000   \n",
       "George Chapman  0.054688  0.031250  0.046875  0.039062  0.007812  0.015625   \n",
       "George Chapman  0.044444  0.000000  0.074074  0.029630  0.000000  0.044444   \n",
       "\n",
       "                      of         a        in     their  \n",
       "Alexander Pope  0.003367  0.006734  0.010101  0.003367  \n",
       "Alexander Pope  0.000000  0.011628  0.023256  0.003322  \n",
       "Alexander Pope  0.003407  0.005111  0.017036  0.020443  \n",
       "Alexander Pope  0.010152  0.000000  0.006768  0.006768  \n",
       "Alexander Pope  0.005146  0.006861  0.012007  0.020583  \n",
       "...                  ...       ...       ...       ...  \n",
       "George Chapman  0.000000  0.008000  0.016000  0.008000  \n",
       "George Chapman  0.016000  0.032000  0.008000  0.008000  \n",
       "George Chapman  0.038462  0.007692  0.007692  0.000000  \n",
       "George Chapman  0.046875  0.000000  0.000000  0.000000  \n",
       "George Chapman  0.007407  0.007407  0.051852  0.007407  \n",
       "\n",
       "[600 rows x 10 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toptopN = 10\n",
    "\n",
    "top_cols = featmatrix.var(axis=0).sort_values(ascending=False)[0:toptopN].index\n",
    "featmatrix = featmatrix[top_cols.tolist()]\n",
    "featmatrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32257645, 0.34791303, 0.32951053],\n",
       "       [0.32463969, 0.34457153, 0.33078878],\n",
       "       [0.32574527, 0.34426337, 0.32999136],\n",
       "       ...,\n",
       "       [0.33211901, 0.33681171, 0.33106927],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33548167, 0.33556891, 0.32894943]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmatrix = createTestMat()\n",
    "\n",
    "model = svm.SVC(kernel='linear', decision_function_shape='ovr')\n",
    "#model = svm.LinearSVC()\n",
    "model.probability = True\n",
    "model.fit(featmatrix, featmatrix.index.tolist())\n",
    "\n",
    "##performance on training set\n",
    "model.predict_proba(featmatrix)\n",
    "#model.predict(testmatrix)\n",
    "\n",
    "#model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>in</th>\n",
       "      <th>his</th>\n",
       "      <th>with</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>before</th>\n",
       "      <th>last</th>\n",
       "      <th>day</th>\n",
       "      <th>name</th>\n",
       "      <th>leave</th>\n",
       "      <th>power</th>\n",
       "      <th>fair</th>\n",
       "      <th>men</th>\n",
       "      <th>only</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.083031</td>\n",
       "      <td>0.039235</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.020298</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.083031</td>\n",
       "      <td>0.039235</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.020298</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the       and        to        be        of         a        in  \\\n",
       "Test  0.083031  0.039235  0.021385  0.008439  0.020031  0.010238  0.015278   \n",
       "Test  0.083031  0.039235  0.021385  0.008439  0.020031  0.010238  0.015278   \n",
       "\n",
       "           his      with       but  ...  before  last       day  name  leave  \\\n",
       "Test  0.020298  0.013985  0.005095  ...     0.0   0.0  0.001648   0.0    0.0   \n",
       "Test  0.020298  0.013985  0.005095  ...     0.0   0.0  0.001648   0.0    0.0   \n",
       "\n",
       "         power  fair  men  only  life  \n",
       "Test  0.001566   0.0  0.0   0.0   0.0  \n",
       "Test  0.001566   0.0  0.0   0.0   0.0  \n",
       "\n",
       "[2 rows x 120 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(training_data, chunks=100):\n",
    "    \n",
    "    textchunks = []\n",
    "    labels = []\n",
    "    for auth in training_data:\n",
    "        #combine all texts into a single string\n",
    "        corpus = ''\n",
    "        for text in training_data[auth]:\n",
    "            corpus = corpus+text+' '\n",
    "        \n",
    "        #get chunk size\n",
    "        sz = int(len(corpus)/chunks)\n",
    "        \n",
    "        #cut corpus into chunks\n",
    "        for i in range(0,len(corpus)-sz,sz):\n",
    "            textchunks.append(corpus[i:i+sz])\n",
    "            labels.append(auth)\n",
    "            \n",
    "    return textchunks, labels\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, authors = chunkify(training_data, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6831000\n"
     ]
    }
   ],
   "source": [
    "topN = 200\n",
    "featmatrix = _makeFeatureMatrix(texts, authors, topN)  ###too many cols, need to have master list of frequent wds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>in</th>\n",
       "      <th>his</th>\n",
       "      <th>with</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>before</th>\n",
       "      <th>last</th>\n",
       "      <th>day</th>\n",
       "      <th>name</th>\n",
       "      <th>leave</th>\n",
       "      <th>power</th>\n",
       "      <th>fair</th>\n",
       "      <th>men</th>\n",
       "      <th>only</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.095960</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.068143</td>\n",
       "      <td>0.051107</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.010221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Pope</th>\n",
       "      <td>0.072041</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George Chapman</th>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     the       and        to        be        of         a  \\\n",
       "Alexander Pope  0.095960  0.040404  0.018519  0.013468  0.003367  0.006734   \n",
       "Alexander Pope  0.058140  0.029900  0.023256  0.008306  0.000000  0.011628   \n",
       "Alexander Pope  0.068143  0.051107  0.020443  0.011925  0.003407  0.005111   \n",
       "Alexander Pope  0.055838  0.037225  0.021997  0.011844  0.010152  0.000000   \n",
       "Alexander Pope  0.072041  0.044597  0.010292  0.012007  0.005146  0.006861   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "George Chapman  0.048000  0.032000  0.008000  0.032000  0.000000  0.008000   \n",
       "George Chapman  0.032000  0.032000  0.016000  0.016000  0.016000  0.032000   \n",
       "George Chapman  0.038462  0.015385  0.015385  0.000000  0.038462  0.007692   \n",
       "George Chapman  0.054688  0.039062  0.007812  0.015625  0.046875  0.000000   \n",
       "George Chapman  0.044444  0.029630  0.000000  0.044444  0.007407  0.007407   \n",
       "\n",
       "                      in       his      with       but  ...  before      last  \\\n",
       "Alexander Pope  0.010101  0.000000  0.005051  0.005051  ...     0.0  0.000000   \n",
       "Alexander Pope  0.023256  0.003322  0.008306  0.011628  ...     0.0  0.000000   \n",
       "Alexander Pope  0.017036  0.003407  0.013629  0.010221  ...     0.0  0.000000   \n",
       "Alexander Pope  0.006768  0.000000  0.010152  0.006768  ...     0.0  0.000000   \n",
       "Alexander Pope  0.012007  0.001715  0.018868  0.003431  ...     0.0  0.000000   \n",
       "...                  ...       ...       ...       ...  ...     ...       ...   \n",
       "George Chapman  0.016000  0.000000  0.000000  0.016000  ...     0.0  0.000000   \n",
       "George Chapman  0.008000  0.032000  0.024000  0.008000  ...     0.0  0.000000   \n",
       "George Chapman  0.007692  0.061538  0.015385  0.000000  ...     0.0  0.000000   \n",
       "George Chapman  0.000000  0.046875  0.039062  0.000000  ...     0.0  0.000000   \n",
       "George Chapman  0.051852  0.074074  0.000000  0.000000  ...     0.0  0.007407   \n",
       "\n",
       "                     day      name     leave     power      fair       men  \\\n",
       "Alexander Pope  0.000000  0.000000  0.000000  0.001684  0.008418  0.000000   \n",
       "Alexander Pope  0.001661  0.003322  0.000000  0.000000  0.000000  0.000000   \n",
       "Alexander Pope  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Alexander Pope  0.003384  0.000000  0.000000  0.003384  0.000000  0.000000   \n",
       "Alexander Pope  0.000000  0.005146  0.003431  0.000000  0.006861  0.000000   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "George Chapman  0.000000  0.000000  0.008000  0.000000  0.000000  0.000000   \n",
       "George Chapman  0.000000  0.000000  0.000000  0.000000  0.000000  0.008000   \n",
       "George Chapman  0.000000  0.000000  0.007692  0.000000  0.000000  0.000000   \n",
       "George Chapman  0.000000  0.000000  0.000000  0.000000  0.000000  0.007812   \n",
       "George Chapman  0.000000  0.000000  0.000000  0.007407  0.000000  0.000000   \n",
       "\n",
       "                only      life  \n",
       "Alexander Pope   0.0  0.000000  \n",
       "Alexander Pope   0.0  0.000000  \n",
       "Alexander Pope   0.0  0.000000  \n",
       "Alexander Pope   0.0  0.000000  \n",
       "Alexander Pope   0.0  0.000000  \n",
       "...              ...       ...  \n",
       "George Chapman   0.0  0.000000  \n",
       "George Chapman   0.0  0.000000  \n",
       "George Chapman   0.0  0.000000  \n",
       "George Chapman   0.0  0.000000  \n",
       "George Chapman   0.0  0.007407  \n",
       "\n",
       "[600 rows x 120 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supertrain = ''\n",
    "for txt in texts:\n",
    "    supertrain = supertrain+txt+' '\n",
    "\n",
    "superprof = _makeProfile('Super', supertrain, topN)\n",
    "mastercols = superprof.columns.tolist()\n",
    "\n",
    "featmatrix = featmatrix[mastercols]\n",
    "featmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measures the similarity between two profiles by the angle formed between them ##\n",
    "def cosSimilarity(p1, p2):\n",
    "    return (p1 @ p2) / (np.linalg.norm(p1) * np.linalg.norm(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-0affa1000476>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprofiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makeFeatureMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-231-ff06242e6498>\u001b[0m in \u001b[0;36m_makeFeatureMatrix\u001b[1;34m(traindict, topN)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mauth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraindict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makeProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraindict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mfeatdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, ignore_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-4e5b04d02a37>\u001b[0m in \u001b[0;36m_makeProfile\u001b[1;34m(auth, text, topN)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Take author and input text, return df (Series) of profiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_makeProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwdlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtotalvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwdlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-ab467af03626>\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Preprocessing: accept string text, return a list of word stems without punct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_v2021_new\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "profiles = _makeFeatureMatrix(training_data, topN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061440474130135"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSimilarity(featmatrix.iloc[0], featmatrix.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict = {'Alexander Pope':[r'\\Pope\\Pope_iliad.txt'], \n",
    "            'John Dryden':[r'\\Dryden\\Dryden_iliad_1_p6.txt'],\n",
    "            #'George Chapman':[r'\\Chapman\\Chapman_iliad.txt']\n",
    "           }\n",
    "\n",
    "\n",
    "for auth in testdict:\n",
    "    flist = testdict[auth]\n",
    "    #clist = []\n",
    "    content = ''\n",
    "    for fi in flist:\n",
    "        txtfile = path+fi\n",
    "        with open(txtfile, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    testdict[auth] = content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestMat():\n",
    "    \n",
    "    testmatrix = pd.DataFrame()\n",
    "    for k in testdict:\n",
    "        pr = _makeProfile('Test', testdict[k], topN)\n",
    "        testmatrix = testmatrix.append(t)\n",
    "\n",
    "    testmatrix = featmatrix.append(testmatrix)\n",
    "    testmatrix.fillna(0, inplace=True)\n",
    "\n",
    "    col_list = featmatrix.columns.tolist()\n",
    "    testmatrix = testmatrix.iloc[-len(testdict):]\n",
    "    testmatrix = testmatrix[col_list]\n",
    "    return testmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3 ## number of authors in training data\n",
    "\n",
    "\n",
    "auth = 'Alexander Pope'\n",
    "#auth = 'John Dryden'\n",
    "t = _makeProfile('Test', testdict[auth], topN)\n",
    "testmatrix = [_makeProfile('Test', testdict[k], topN) for k in testdict]\n",
    "testmatrix = pd.DataFrame(testmatrix)\n",
    "\n",
    "temp = featmatrix.append(t)\n",
    "temp.fillna(0, inplace=True)\n",
    "\n",
    "t = temp.iloc[M] #last row of dataframe\n",
    "\n",
    "comp = temp.iloc[2]\n",
    "cosSimilarity(comp, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [3,3,5,2,1,5,7,3]\n",
    "a[-3:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Pope : 0.9331173121099801\n",
      "John Dryden : 0.2936867858564023\n",
      "George Chapman : 0.8475553509245354\n",
      "[0.44983395 0.14157951 0.40858654]\n"
     ]
    }
   ],
   "source": [
    "dist = []\n",
    "for i in range(M): #0 to -M-1 i.e. training set\n",
    "    comp = temp.iloc[i]\n",
    "    dist.append(cosSimilarity(comp, t))\n",
    "    print(temp.index[i],':', dist[i])\n",
    "    \n",
    "print(dist/sum(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Alexander Pope', 'John Dryden', 'George Chapman', 'Test'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

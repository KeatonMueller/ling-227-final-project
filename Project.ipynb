{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calculate_prf(matrix):\n",
    "    '''\n",
    "    Calculates precision, recall, and F1 score for the given\n",
    "    confusion matrix. MUST be a simple 2x2 confusion matrix.\n",
    "    \n",
    "    Handles division by zero cases based on the following\n",
    "    methodology: https://github.com/dice-group/gerbil/wiki/Precision,-Recall-and-F1-measure\n",
    "    \n",
    "    returns (precision, recall, F1 score) tuple\n",
    "    '''\n",
    "    if matrix['tp'] == 0:\n",
    "        if matrix['fp'] == 0 and matrix['fn'] == 0:\n",
    "            return 1.0, 1.0, 1.0\n",
    "        if matrix['fp'] == 0 or matrix['fn'] == 0:\n",
    "            return 0, 0, 0\n",
    "    \n",
    "    precision = matrix['tp'] / (matrix['tp'] + matrix['fp'])\n",
    "    recall = matrix['tp'] / (matrix['tp'] + matrix['fn'])\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def test_model(model, training_data, test_data):\n",
    "    '''\n",
    "    Function to test `model` on `test_data` given `training_data`.\n",
    "    `test_data` is a list of (text, label) tuples.\n",
    "    \n",
    "    return (micro_f1, macro_f1, confusion_matrix) tuple\n",
    "    '''\n",
    "    model.train(training_data)\n",
    "    \n",
    "    # confusion matrix to store results used for calculating precision and recall\n",
    "    # confusion_matrix[gold_label][model_label] = number of occurrences\n",
    "    confusion_matrix = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    \n",
    "    for text, gold_label in test_data:\n",
    "        model_label = model.identify(text)[0][1]        \n",
    "        confusion_matrix[gold_label][model_label] += 1\n",
    "    \n",
    "    # compute individual class matrices\n",
    "    class_matrix = {}\n",
    "    num_results = sum([sum(confusion_matrix[auth].values()) for auth in confusion_matrix])\n",
    "    \n",
    "    for auth in confusion_matrix:\n",
    "        class_matrix[auth] = {\n",
    "            'tp': confusion_matrix[auth][auth],\n",
    "            'fp': sum([confusion_matrix[i][auth] for i in confusion_matrix if i != auth]),\n",
    "            'fn': sum(confusion_matrix[auth].values()) - confusion_matrix[auth][auth]\n",
    "        }\n",
    "        class_matrix[auth]['tn'] = num_results - sum(class_matrix[auth].values())\n",
    "        \n",
    "    # compute a pooled matrix\n",
    "    pooled_matrix = {\n",
    "        'tp': sum([class_matrix[auth]['tp'] for auth in class_matrix]),\n",
    "        'fp': sum([class_matrix[auth]['fp'] for auth in class_matrix]),\n",
    "        'tn': sum([class_matrix[auth]['tn'] for auth in class_matrix]),\n",
    "        'fn': sum([class_matrix[auth]['fn'] for auth in class_matrix])\n",
    "    }\n",
    "    \n",
    "    # micro precision, recall, and F1\n",
    "    micro_precision, micro_recall, micro_f1 = calculate_prf(pooled_matrix)\n",
    "\n",
    "    # macro precision, recall, and F1\n",
    "    class_precision = {}\n",
    "    class_recall = {}\n",
    "    \n",
    "    for auth in class_matrix:\n",
    "        p, r, _ = calculate_prf(class_matrix[auth])\n",
    "        class_precision[auth] = p\n",
    "        class_recall[auth] = r\n",
    "    \n",
    "    macro_precision = sum(class_precision.values()) / len(class_precision)\n",
    "    macro_recall = sum(class_recall.values()) / len(class_recall)\n",
    "    macro_f1 = (2 * macro_precision * macro_recall) / (macro_precision + macro_recall)\n",
    "    \n",
    "    # return F1 scores and confusion matrix\n",
    "    return micro_f1, macro_f1, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_model import Ensemble\n",
    "from models.compression_model import CompressionModel\n",
    "from utils.data_reader import read_data\n",
    "\n",
    "# initialize ensemble model\n",
    "model = CompressionModel()\n",
    "\n",
    "# read in the data\n",
    "data = read_data()\n",
    "# training data is everything but the iliad\n",
    "# NOTE: should almost certainly change this, this is just to get us started\n",
    "training_data = { auth: texts[1:] for auth, texts in data.items() }\n",
    "\n",
    "# make test data the iliad split on different sections\n",
    "test_data = []\n",
    "i = 0\n",
    "for auth in data:\n",
    "    iliad = data[auth][0]\n",
    "    for section in iliad.split('\\n\\n'):\n",
    "        test_data.append((section, auth))\n",
    "\n",
    "test_model(model, training_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_model import AbstractModel\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing: accept string text, return a list of word stems\n",
    "def _preprocess(text):\n",
    "    text = re.sub('\\s', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    temp = [c for c in text if c not in string.punctuation]\n",
    "    text_clean = ''.join(temp)\n",
    "    \n",
    "    li = text_clean.split(' ')\n",
    "    lemm = WordNetLemmatizer()\n",
    "    wdlist = [lemm.lemmatize(wd, pos=\"v\") for wd in li]\n",
    "    \n",
    "    return wdlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Take author and input text, return df (Series) of profiles\n",
    "def _makeProfile(self, auth, text):\n",
    "    wdlist = _preprocess(text)\n",
    "\n",
    "    totalvocab = len(wdlist)\n",
    "\n",
    "    fd = FreqDist(wdlist)\n",
    "    commonwords = dict(fd.most_common(self.topN))\n",
    "    df = pd.DataFrame.from_dict(commonwords, orient='index', columns=[auth])\n",
    "    df = df/totalvocab #normalize\n",
    "    df = df.transpose()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert text to features\n",
    "def _makeFeatureMatrix(self, training_data):\n",
    "    \n",
    "    featdf = pd.DataFrame()\n",
    "    \n",
    "    for auth in training_data:\n",
    "        text = training_data[auth]\n",
    "        \n",
    "        df = _makeProfile(self, auth, text)\n",
    "        \n",
    "        featdf = featdf.append(df) #, ignore_index=True)\n",
    "\n",
    "    featdf.fillna(0, inplace=True)\n",
    "        \n",
    "    #print(featdf)\n",
    "    return featdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measures the similarity between two profiles by the angle formed between them ##\n",
    "def _cosSimilarity(p1, p2):\n",
    "    return (p1 @ p2) / (np.linalg.norm(p1) * np.linalg.norm(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, training_data, topN=100):\n",
    "    ##TODO: call _makeFeatureMatrix and convert to desired data structure of o/p profiles\n",
    "    \n",
    "    self.topN = topN\n",
    "    \n",
    "    traindict = {}\n",
    "    for auth in training_data:\n",
    "        corpus = ''\n",
    "        for text in training_data[auth]:\n",
    "            corpus = corpus+text+' '\n",
    "        traindict[auth] = corpus\n",
    "    \n",
    "    featmatrix = _makeFeatureMatrix(self, traindict)\n",
    "    \n",
    "    self.profiledf = featmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify(self, text):\n",
    "    \n",
    "    testdf = _createTest(self, text)\n",
    "    authors = self.profiledf.index.tolist()\n",
    "    \n",
    "    M = len(self.profiledf)\n",
    "    clist = []\n",
    "    for i in range(M):\n",
    "        clist.append(cosSimilarity(self.profiledf.iloc[i], testdf.iloc[0]))\n",
    "    \n",
    "    probdict = {}\n",
    "    for i in range(M):\n",
    "        probdict[authors[i]] = clist[i]/sum(clist)\n",
    "        \n",
    "    idlist = sorted([(clist[i]/sum(clist), authors[i]) for i in range(M)], reverse=True)\n",
    "        \n",
    "    return idlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _createTest(self, text):\n",
    "    \n",
    "    featmatrix = self.profiledf\n",
    "    \n",
    "    pr = _makeProfile(self, 'Test', text)\n",
    "    \n",
    "    testdf = featmatrix.append(pr)\n",
    "    testdf.fillna(0, inplace=True)\n",
    "\n",
    "    col_list = featmatrix.columns.tolist()\n",
    "    testdf = testdf.iloc[-1]\n",
    "    \n",
    "    return testdf[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_frequency_model import BOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read training data - V BRUTE FORCE\n",
    "\n",
    "path = r'C:\\Users\\shala\\classify3\\ling-227-final-project\\texts'\n",
    "filedict = {'Alexander Pope':[r'\\Pope\\Pope_train1.txt', r'\\Pope\\Pope_train2.txt'],\n",
    "            'John Dryden': [r'\\Dryden\\Dryden_train1.txt', r'\\Dryden\\Dryden_train2.txt'],\n",
    "            'George Chapman':[r'\\Chapman\\Chapman_train1.txt', r'\\Chapman\\Chapman_train2.txt',\n",
    "                             r'\\Chapman\\Chapman_train3.txt', r'\\Chapman\\Chapman_train4.txt']}\n",
    "\n",
    "training_data = {'Alexander Pope':[], 'John Dryden':[], 'George Chapman':[]}\n",
    "\n",
    "for auth in filedict:\n",
    "    flist = filedict[auth]\n",
    "    #clist = []\n",
    "    content = ''\n",
    "    for fi in flist:\n",
    "        txtfile = path+fi\n",
    "        with open(txtfile, 'r', encoding='utf-8') as f:\n",
    "            ogtext = f.read()\n",
    "            training_data[auth].append(ogtext)\n",
    "            #clist.append(ogtext)\n",
    "            #content = content+ogtext+' '\n",
    "    #filedict[auth] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_makeFeatureMatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ba343e568b2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBOW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mBOW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\classify3\\ling-227-final-project\\models\\word_frequency_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, training_data, topN)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mtraindict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mfeatmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makeFeatureMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraindict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiledf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_makeFeatureMatrix' is not defined"
     ]
    }
   ],
   "source": [
    "model = BOW()\n",
    "BOW.train(model, training_data) ##???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
